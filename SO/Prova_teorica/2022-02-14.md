# 2022-02-14

## c.1
```C
monitor semdata {
  int ndP;
  int ndV;

  condition canP;
  Stack<datatype> elements;

  datatype dp() {
    // Non possiamo fare la P
    // se ndP <= ndV
    if (ndP + 1 < ndV) {
      canP.wait();
    }
    ++ndP;
    // Se si può fare la P o
    // abbiamo ricevuto una signal
    // possiamo restituire l'ultimo dato inserito
    return elements.pop()
  }

  void dV(datatype data) {
    // Inserisce un valore 
    // e sblocca una p che era bloccata
    elements.push(data);
    ++ndV;
    if (npP >= ndV)
      canP.signal();
  }
}
```
## c.2
message passing asincrono --> send non bloccante, recieve bloccante

Utilizziamo una struttura dati  messages che per ogni pid(compreso ANY), mantiene una coda di messaggi.
Il metodo getElement restituisce l'elemento corrispondete all'indice inserito, se è 0 restituisce l'utlimo altrimenti null


```Python

Map<pid_t, Queue<msg>> messages
Queue<msgtype> anyQueue

void snsend(msgtype msg, pid_t dest) {
  asend((getpid(), msg), dest)
  ack = arecv(dest)
}

msgtype snrecv(pid_t sender, int n) {
  l = null
  if (sender == ANY):
    l = anyQueue
  else:
    l = messages
  # Dobbiamo continuare a ricevere finchè non ci arriva il messaggio
  # che vogliamo
  res = null
  while ((res = getElement(l, n)) == NULL):
    (pid, msg) = arecv(sender)
    asend (pid, ACK)
    anyQueue.insert(msg)
    messages[pid].insert(msg)
  return res

}

```

## g.1


## g.2

* a) Viene utilizzata la paginazione perchè introduce già da sola meccanismi di traslazione tra indirizzi logici e fisici, inoltre le pagine hanno dimensione fissa ed è quindi comodo fare swap in e swap out nel caso in cui una pagina di un processo non sia in memoria principale ma nella secondaria. In questo modo un processo ha un numero di pagine associato e attraverso un bit si indica se la pagina è in memoria oppure no.

* b) L'algoritmo del banchiere viene chiamato ogni volta che si richiede o si rilascia una risorsa. Esso determina se con l'attuale distribuzione delle risorse esiste una sequenza di richieste che permetta di soddisfarle tutte. Se il risultato è safe vuol dire che non si rischiano stati di deadlock e quindi cede le risorse, se è unsafe il processo che ha fatto la richiesta viene messo in attesa e viene ripristinato l'ultimo stato safe.

* c) File system con allocazione contigua permettono accesso diretto e sequenziale efficienti, di conseguenza utilizzare altri tipi di allocazione che non permettono ciò causerebbe un calo delle prestazioni.

* d) In quanto permettono un utilizzo più efficiente delle risorse ed evitano il busy waiting da parte del processore per controllare periodicamente se un dispositivo ha terminato il suo compito.
